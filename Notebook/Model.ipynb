{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Stroke Predication Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Libraries:\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for displaying all feature from dataset:\n",
    "pd.pandas.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reading the Preprocessed dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender_Male</th>\n",
       "      <th>age</th>\n",
       "      <th>hypertension</th>\n",
       "      <th>heart_disease</th>\n",
       "      <th>ever_married</th>\n",
       "      <th>Residence_type</th>\n",
       "      <th>avg_glucose_level</th>\n",
       "      <th>bmi</th>\n",
       "      <th>work_type_Never_worked</th>\n",
       "      <th>work_type_Private</th>\n",
       "      <th>work_type_Self-employed</th>\n",
       "      <th>work_type_children</th>\n",
       "      <th>smoking_status_formerly_smoked</th>\n",
       "      <th>smoking_status_never_smoked</th>\n",
       "      <th>smoking_status_smokes</th>\n",
       "      <th>stroke</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>228.69</td>\n",
       "      <td>36.6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>202.21</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>105.92</td>\n",
       "      <td>32.5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>171.23</td>\n",
       "      <td>34.4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>174.12</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   gender_Male   age  hypertension  heart_disease  ever_married  \\\n",
       "0            1  67.0             0              1             1   \n",
       "1            0  61.0             0              0             1   \n",
       "2            1  80.0             0              1             1   \n",
       "3            0  49.0             0              0             1   \n",
       "4            0  79.0             1              0             1   \n",
       "\n",
       "   Residence_type  avg_glucose_level   bmi  work_type_Never_worked  \\\n",
       "0               0             228.69  36.6                       0   \n",
       "1               1             202.21  28.1                       0   \n",
       "2               1             105.92  32.5                       0   \n",
       "3               0             171.23  34.4                       0   \n",
       "4               1             174.12  24.0                       0   \n",
       "\n",
       "   work_type_Private  work_type_Self-employed  work_type_children  \\\n",
       "0                  1                        0                   0   \n",
       "1                  0                        1                   0   \n",
       "2                  1                        0                   0   \n",
       "3                  1                        0                   0   \n",
       "4                  0                        1                   0   \n",
       "\n",
       "   smoking_status_formerly_smoked  smoking_status_never_smoked  \\\n",
       "0                               1                            0   \n",
       "1                               0                            1   \n",
       "2                               0                            1   \n",
       "3                               0                            0   \n",
       "4                               0                            1   \n",
       "\n",
       "   smoking_status_smokes  stroke  \n",
       "0                      0       1  \n",
       "1                      0       1  \n",
       "2                      0       1  \n",
       "3                      1       1  \n",
       "4                      0       1  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reading Dataset:\n",
    "df = pd.read_csv(\"Stroke_data.csv\")\n",
    "# Top 5 records:\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attribute Information\n",
    "1) id: unique identifier <br>\n",
    "2) gender: \"Male\", \"Female\" or \"Other\" <br>\n",
    "3) age: age of the patient <br>\n",
    "4) hypertension: 0 if the patient doesn't have hypertension, 1 if the patient has hypertension <br>\n",
    "5) heart_disease: 0 if the patient doesn't have any heart diseases, 1 if the patient has a heart disease <br>\n",
    "6) ever_married: \"No\" or \"Yes\" <br>\n",
    "7) work_type: \"children\", \"Govt_jov\", \"Never_worked\", \"Private\" or \"Self-employed\" <br>\n",
    "8) Residence_type: \"Rural\" or \"Urban\" <br>\n",
    "9) avg_glucose_level: average glucose level in blood <br>\n",
    "10) bmi: body mass index <br>\n",
    "11) smoking_status: \"formerly smoked\", \"never smoked\", \"smokes\" or \"Unknown\"* <br>\n",
    "12) stroke: 1 if the patient had a stroke or 0 if not <br>\n",
    "*Note: \"Unknown\" in smoking_status means that the information is unavailable for this patient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### # Dependent & Independent Feature:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.iloc[:, :-1]\n",
    "y = df.iloc[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender_Male</th>\n",
       "      <th>age</th>\n",
       "      <th>hypertension</th>\n",
       "      <th>heart_disease</th>\n",
       "      <th>ever_married</th>\n",
       "      <th>Residence_type</th>\n",
       "      <th>avg_glucose_level</th>\n",
       "      <th>bmi</th>\n",
       "      <th>work_type_Never_worked</th>\n",
       "      <th>work_type_Private</th>\n",
       "      <th>work_type_Self-employed</th>\n",
       "      <th>work_type_children</th>\n",
       "      <th>smoking_status_formerly_smoked</th>\n",
       "      <th>smoking_status_never_smoked</th>\n",
       "      <th>smoking_status_smokes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>228.69</td>\n",
       "      <td>36.6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>202.21</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>105.92</td>\n",
       "      <td>32.5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>171.23</td>\n",
       "      <td>34.4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>174.12</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   gender_Male   age  hypertension  heart_disease  ever_married  \\\n",
       "0            1  67.0             0              1             1   \n",
       "1            0  61.0             0              0             1   \n",
       "2            1  80.0             0              1             1   \n",
       "3            0  49.0             0              0             1   \n",
       "4            0  79.0             1              0             1   \n",
       "\n",
       "   Residence_type  avg_glucose_level   bmi  work_type_Never_worked  \\\n",
       "0               0             228.69  36.6                       0   \n",
       "1               1             202.21  28.1                       0   \n",
       "2               1             105.92  32.5                       0   \n",
       "3               0             171.23  34.4                       0   \n",
       "4               1             174.12  24.0                       0   \n",
       "\n",
       "   work_type_Private  work_type_Self-employed  work_type_children  \\\n",
       "0                  1                        0                   0   \n",
       "1                  0                        1                   0   \n",
       "2                  1                        0                   0   \n",
       "3                  1                        0                   0   \n",
       "4                  0                        1                   0   \n",
       "\n",
       "   smoking_status_formerly_smoked  smoking_status_never_smoked  \\\n",
       "0                               1                            0   \n",
       "1                               0                            1   \n",
       "2                               0                            1   \n",
       "3                               0                            0   \n",
       "4                               0                            1   \n",
       "\n",
       "   smoking_status_smokes  \n",
       "0                      0  \n",
       "1                      0  \n",
       "2                      0  \n",
       "3                      1  \n",
       "4                      0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### # Train-Test Split:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4087, 15)\n",
      "(1022, 15)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Performance Metrics:\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### # RandomForestClassifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9461839530332681\n",
      "[[967   1]\n",
      " [ 54   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.97       968\n",
      "           1       0.00      0.00      0.00        54\n",
      "\n",
      "    accuracy                           0.95      1022\n",
      "   macro avg       0.47      0.50      0.49      1022\n",
      "weighted avg       0.90      0.95      0.92      1022\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "RandomForest = RandomForestClassifier()\n",
    "RandomForest = RandomForest.fit(X_train,y_train)\n",
    "\n",
    "# Predictions:\n",
    "y_pred = RandomForest.predict(X_test)\n",
    "\n",
    "# Performance:\n",
    "print('Accuracy:', accuracy_score(y_test,y_pred))\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9461839530332681\n",
      "[[966   2]\n",
      " [ 53   1]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.97       968\n",
      "           1       0.33      0.02      0.04        54\n",
      "\n",
      "    accuracy                           0.95      1022\n",
      "   macro avg       0.64      0.51      0.50      1022\n",
      "weighted avg       0.92      0.95      0.92      1022\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# AdaBoostClassifier:\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "AdaBoost = AdaBoostClassifier()\n",
    "AdaBoost = AdaBoost.fit(X_train,y_train)\n",
    "\n",
    "# Predictions:\n",
    "y_pred = AdaBoost.predict(X_test)\n",
    "\n",
    "# Performance:\n",
    "print('Accuracy:', accuracy_score(y_test,y_pred))\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9461839530332681\n",
      "[[966   2]\n",
      " [ 53   1]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.97       968\n",
      "           1       0.33      0.02      0.04        54\n",
      "\n",
      "    accuracy                           0.95      1022\n",
      "   macro avg       0.64      0.51      0.50      1022\n",
      "weighted avg       0.92      0.95      0.92      1022\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# GradientBoostingClassifier:\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "GradientBoost = GradientBoostingClassifier()\n",
    "GradientBoost = GradientBoost.fit(X_train,y_train)\n",
    "\n",
    "# Predictions:\n",
    "y_pred = GradientBoost.predict(X_test)\n",
    "\n",
    "# Performance:\n",
    "print('Accuracy:', accuracy_score(y_test,y_pred))\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, 120, 130, 140, 150, 160, 170, 180, 190, 200], 'max_features': ['auto', 'sqrt', 'log2'], 'max_depth': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, 120, 130, 140, 150, 160, 170, 180, 190, 200], 'min_samples_split': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 12, 14, 16, 18, 20], 'min_samples_leaf': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 12, 14, 16, 18, 20], 'criterion': ['entropy', 'gini']}\n",
      "Fitting 10 folds for each of 100 candidates, totalling 1000 fits\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=10, estimator=RandomForestClassifier(), n_iter=100,\n",
       "                   n_jobs=-1,\n",
       "                   param_distributions={&#x27;criterion&#x27;: [&#x27;entropy&#x27;, &#x27;gini&#x27;],\n",
       "                                        &#x27;max_depth&#x27;: [10, 20, 30, 40, 50, 60,\n",
       "                                                      70, 80, 90, 100, 110, 120,\n",
       "                                                      130, 140, 150, 160, 170,\n",
       "                                                      180, 190, 200],\n",
       "                                        &#x27;max_features&#x27;: [&#x27;auto&#x27;, &#x27;sqrt&#x27;,\n",
       "                                                         &#x27;log2&#x27;],\n",
       "                                        &#x27;min_samples_leaf&#x27;: [1, 2, 3, 4, 5, 6,\n",
       "                                                             7, 8, 9, 10, 12,\n",
       "                                                             14, 16, 18, 20],\n",
       "                                        &#x27;min_samples_split&#x27;: [1, 2, 3, 4, 5, 6,\n",
       "                                                              7, 8, 9, 10, 12,\n",
       "                                                              14, 16, 18, 20],\n",
       "                                        &#x27;n_estimators&#x27;: [10, 20, 30, 40, 50, 60,\n",
       "                                                         70, 80, 90, 100, 110,\n",
       "                                                         120, 130, 140, 150,\n",
       "                                                         160, 170, 180, 190,\n",
       "                                                         200]},\n",
       "                   random_state=0, verbose=2)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomizedSearchCV</label><div class=\"sk-toggleable__content\"><pre>RandomizedSearchCV(cv=10, estimator=RandomForestClassifier(), n_iter=100,\n",
       "                   n_jobs=-1,\n",
       "                   param_distributions={&#x27;criterion&#x27;: [&#x27;entropy&#x27;, &#x27;gini&#x27;],\n",
       "                                        &#x27;max_depth&#x27;: [10, 20, 30, 40, 50, 60,\n",
       "                                                      70, 80, 90, 100, 110, 120,\n",
       "                                                      130, 140, 150, 160, 170,\n",
       "                                                      180, 190, 200],\n",
       "                                        &#x27;max_features&#x27;: [&#x27;auto&#x27;, &#x27;sqrt&#x27;,\n",
       "                                                         &#x27;log2&#x27;],\n",
       "                                        &#x27;min_samples_leaf&#x27;: [1, 2, 3, 4, 5, 6,\n",
       "                                                             7, 8, 9, 10, 12,\n",
       "                                                             14, 16, 18, 20],\n",
       "                                        &#x27;min_samples_split&#x27;: [1, 2, 3, 4, 5, 6,\n",
       "                                                              7, 8, 9, 10, 12,\n",
       "                                                              14, 16, 18, 20],\n",
       "                                        &#x27;n_estimators&#x27;: [10, 20, 30, 40, 50, 60,\n",
       "                                                         70, 80, 90, 100, 110,\n",
       "                                                         120, 130, 140, 150,\n",
       "                                                         160, 170, 180, 190,\n",
       "                                                         200]},\n",
       "                   random_state=0, verbose=2)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomizedSearchCV(cv=10, estimator=RandomForestClassifier(), n_iter=100,\n",
       "                   n_jobs=-1,\n",
       "                   param_distributions={'criterion': ['entropy', 'gini'],\n",
       "                                        'max_depth': [10, 20, 30, 40, 50, 60,\n",
       "                                                      70, 80, 90, 100, 110, 120,\n",
       "                                                      130, 140, 150, 160, 170,\n",
       "                                                      180, 190, 200],\n",
       "                                        'max_features': ['auto', 'sqrt',\n",
       "                                                         'log2'],\n",
       "                                        'min_samples_leaf': [1, 2, 3, 4, 5, 6,\n",
       "                                                             7, 8, 9, 10, 12,\n",
       "                                                             14, 16, 18, 20],\n",
       "                                        'min_samples_split': [1, 2, 3, 4, 5, 6,\n",
       "                                                              7, 8, 9, 10, 12,\n",
       "                                                              14, 16, 18, 20],\n",
       "                                        'n_estimators': [10, 20, 30, 40, 50, 60,\n",
       "                                                         70, 80, 90, 100, 110,\n",
       "                                                         120, 130, 140, 150,\n",
       "                                                         160, 170, 180, 190,\n",
       "                                                         200]},\n",
       "                   random_state=0, verbose=2)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 10, stop = 200, num = 20)]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt','log2']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 200,20)]\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [1,2,3,4,5,6,7,8,9,10,12,14,16,18,20]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1,2,3,4,5,6,7,8,9,10,12,14,16,18,20]\n",
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "              'criterion':['entropy','gini']}\n",
    "print(random_grid)\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "rf_randomcv = RandomizedSearchCV(estimator=rf,param_distributions=random_grid,n_iter=100,cv=10,verbose=2,\n",
    "                               random_state=0,n_jobs=-1)\n",
    "### fit the randomized model\n",
    "rf_randomcv.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 120,\n",
       " 'min_samples_split': 1,\n",
       " 'min_samples_leaf': 20,\n",
       " 'max_features': 'sqrt',\n",
       " 'max_depth': 30,\n",
       " 'criterion': 'gini'}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_randomcv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9471624266144814\n",
      "[[968   0]\n",
      " [ 54   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.97       968\n",
      "           1       0.00      0.00      0.00        54\n",
      "\n",
      "    accuracy                           0.95      1022\n",
      "   macro avg       0.47      0.50      0.49      1022\n",
      "weighted avg       0.90      0.95      0.92      1022\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\hp\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\hp\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "RandomForest_RandomCV = RandomForestClassifier(criterion='gini', n_estimators=100, max_depth=130, max_features='auto', min_samples_split=14, min_samples_leaf=16)\n",
    "RandomForest_RandomCV = RandomForest_RandomCV.fit(X_train,y_train)\n",
    "\n",
    "# Predictions:\n",
    "y_pred = RandomForest_RandomCV.predict(X_test)\n",
    "\n",
    "# Performance:\n",
    "print('Accuracy:', accuracy_score(y_test,y_pred))\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ----------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SMOTE\n",
    "\n",
    "\n",
    "**SMOTE (Synthetic Minority Over-sampling Technique) is a popular technique used in data science and machine learning to address class imbalance in datasets. Class imbalance occurs when the classes in the target variable are not represented equally, resulting in a skewed distribution.**\n",
    "\n",
    "**SMOTE works by generating synthetic samples for the minority class to increase its representation in the dataset. It creates new synthetic instances by interpolating between existing minority class samples. The algorithm selects a random sample from the minority class, identifies its k nearest neighbors, and creates synthetic samples by combining the attributes of the selected sample and its neighbors.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import delayed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.combine import SMOTETomek\n",
    "smote = SMOTETomek()\n",
    "X_smote, y_smote = smote.fit_resample(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before SMOTE :  Counter({0: 4860, 1: 249})\n",
      "After SMOTE  :  Counter({1: 4817, 0: 4817})\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "print('Before SMOTE : ', Counter(y))\n",
    "print('After SMOTE  : ', Counter(y_smote))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9486248053969901\n",
      "[[889  57]\n",
      " [ 42 939]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.94      0.95       946\n",
      "           1       0.94      0.96      0.95       981\n",
      "\n",
      "    accuracy                           0.95      1927\n",
      "   macro avg       0.95      0.95      0.95      1927\n",
      "weighted avg       0.95      0.95      0.95      1927\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train Test Split:\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_smote,y_smote, test_size=0.2, random_state=0)\n",
    "\n",
    "# RandomForestClassifier:\n",
    "RandomForest = RandomForestClassifier()\n",
    "RandomForest = RandomForest.fit(X_train,y_train)\n",
    "\n",
    "# Predictions:\n",
    "y_pred = RandomForest.predict(X_test)\n",
    "\n",
    "# Performance:\n",
    "print('Accuracy:', accuracy_score(y_test,y_pred))\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Over Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "oversampler = RandomOverSampler(sampling_strategy=0.4)\n",
    "x_oversampler, y_oversampler = oversampler.fit_resample(X, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before RandomOverSampler :  Counter({0: 4860, 1: 249})\n",
      "After RandomOverSampler  :  Counter({0: 4860, 1: 1944})\n"
     ]
    }
   ],
   "source": [
    "print('Before RandomOverSampler : ', Counter(y))\n",
    "print('After RandomOverSampler  : ', Counter(y_oversampler))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- #### We make 60-40% data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9904481998530492\n",
      "[[965  11]\n",
      " [  2 383]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99       976\n",
      "           1       0.97      0.99      0.98       385\n",
      "\n",
      "    accuracy                           0.99      1361\n",
      "   macro avg       0.99      0.99      0.99      1361\n",
      "weighted avg       0.99      0.99      0.99      1361\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train Test Split:\n",
    "X_train, X_test, y_train, y_test = train_test_split(x_oversampler,y_oversampler, test_size=0.2, random_state=0)\n",
    "\n",
    "# RandomForestClassifier:\n",
    "RandomForest = RandomForestClassifier()\n",
    "RandomForest = RandomForest.fit(X_train,y_train)\n",
    "\n",
    "# Predictions:\n",
    "y_pred = RandomForest.predict(X_test)\n",
    "\n",
    "# Performance:\n",
    "print('Accuracy:', accuracy_score(y_test,y_pred))\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
